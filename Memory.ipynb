{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571c193d-1821-4f8e-b056-ab2b4092ca10",
   "metadata": {},
   "source": [
    "# LangChain 核心模块:Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e44dd0-b10d-49aa-bfe1-993707b7e8ab",
   "metadata": {},
   "source": [
    "大多数LLM都具有对话界面。对话的一个重要组成部分是能够引进在对话中介绍过的信息。至少，一个对话系统应该能够直接访问一些过去消息的接口。\n",
    "\n",
    "**我们将储存过去交互信息的能力称之为\"记忆 Memory\"**\n",
    "\n",
    "LangChain提供链了许多向应用/系统添加Memory的工具，一个记忆系统需要支持两个基本的操作：**读取和写入**\n",
    "\n",
    "在一个典型的Chain的单次运行中，将与其Memeory System进行至少两次交互:\n",
    "- 在接收到初始化用户输入之后，在执行核心逻辑之前,链将从其Memory中读取并扩充用户输入\n",
    "- 在执行核心逻辑之后但在返回答案之前，一条链将把当前运行的输入和输出写入Memory,以便在未来运行中可以引用他们\n",
    "\n",
    "![](./picture/memory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b94f6-6565-4ee3-b507-ea6047669e6f",
   "metadata": {},
   "source": [
    "## BaseMemory Class 基类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835808ea-dba5-4a57-9555-f698dcd96e6f",
   "metadata": {},
   "source": [
    "\n",
    "类继承关系：\n",
    "\n",
    "```\n",
    "## 适用于简单的语言模型\n",
    "BaseMemory --> BaseChatMemory --> <name>Memory  # Examples: ZepMemory, MotorheadMemory\n",
    "```\n",
    "\n",
    "**代码实现：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/schema/memory.py**\n",
    "\n",
    "```python\n",
    "# 定义一个名为BaseMemory的基础类\n",
    "class BaseMemory(Serializable, ABC):\n",
    "    \"\"\"用于Chains中的内存的抽象基类。\n",
    "    \n",
    "    这里的内存指的是Chains中的状态。内存可以用来存储关于Chain的过去执行的信息，\n",
    "    并将该信息注入到Chain的未来执行的输入中。例如，对于会话型Chains，内存可以用来\n",
    "    存储会话，并自动将它们添加到未来的模型提示中，以便模型具有必要的上下文来连贯地\n",
    "    响应最新的输入。\"\"\"\n",
    "\n",
    "    # 定义一个名为Config的子类\n",
    "    class Config:\n",
    "        \"\"\"为此pydantic对象配置。\n",
    "    \n",
    "        Pydantic是一个Python库，用于数据验证和设置管理，主要基于Python类型提示。\n",
    "        \"\"\"\n",
    "    \n",
    "        # 允许在pydantic模型中使用任意类型。这通常用于允许复杂的数据类型。\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    # 下面是一些必须由子类实现的方法：\n",
    "    \n",
    "    # 定义一个属性，它是一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
    "    # 此方法应返回该内存类将添加到链输入的字符串键。\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def memory_variables(self) -> List[str]:\n",
    "        \"\"\"获取此内存类将添加到链输入的字符串键。\"\"\"\n",
    "    \n",
    "    # 定义一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
    "    # 此方法基于给定的链输入返回键值对。\n",
    "    @abstractmethod\n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"根据给链的文本输入返回键值对。\"\"\"\n",
    "    \n",
    "    # 定义一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
    "    # 此方法将此链运行的上下文保存到内存。\n",
    "    @abstractmethod\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"保存此链运行的上下文到内存。\"\"\"\n",
    "    \n",
    "    # 定义一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
    "    # 此方法清除内存内容。\n",
    "    @abstractmethod\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"清除内存内容。\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1aeee-2dc0-430c-a156-063ce0067226",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3991d-62ed-429f-8999-c38d641dd5de",
   "metadata": {},
   "source": [
    "`ConversationBufferMemory` 可以用来存储消息，并将消息提取到一个变量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e71e9e6-830a-4bf9-8278-4f397de0960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi,there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm=OpenAI(\n",
    "    openai_api_key=\"sk-SJBPQGvGY6P31aLpks0X6s1VaR75hgPlvdF181UESvtLNMer\", \n",
    "    openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "conversion = ConversationChain(llm=llm, verbose=True, memory=ConversationBufferMemory())\n",
    "\n",
    "conversion.predict(input=\"Hi,there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf1e00d-2fb8-4ef0-9100-7c17b7b7dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi,there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to hear! I'm here to chat and answer any questions you may have. What would you like to talk about?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0451a5d-8c6e-4b8a-ae35-0a6adff21cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi,there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI: That's great to hear! I'm here to chat and answer any questions you may have. What would you like to talk about?\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am an AI language model developed by OpenAI. I have been trained on a large dataset of text from the internet, which allows me to generate responses based on patterns and information I have learned. I can assist with a wide range of topics, from answering questions to engaging in casual conversation. Is there anything specific you would like to know about me?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion.predict(input=\"Tell me about yourself.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b39a0f-4bfd-4dcc-b286-29dfeb1e4d22",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e07496-bdaa-4bba-8a30-c88d4124d53a",
   "metadata": {},
   "source": [
    "`ConversationBufferWindowMemory` 会在时间轴上保留对话的交互列表。它只使用最后 K 次交互。这对于保持最近交互的滑动窗口非常有用，以避免缓冲区过大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9f9dc9-abbc-4bdd-add2-94eadf899363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunmzhao/Desktop/project/langchain_study/venv/lib/python3.11/site-packages/langchain/llms/openai.py:201: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/kunmzhao/Desktop/project/langchain_study/venv/lib/python3.11/site-packages/langchain/llms/openai.py:786: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm an AI designed to assist with various tasks and provide information. Right now, I'm here to chat with you. How can I help you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(\n",
    "    openai_api_key=\"sk-SJBPQGvGY6P31aLpks0X6s1VaR75hgPlvdF181UESvtLNMer\", \n",
    "    openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    "),\n",
    "    memory=ConversationBufferWindowMemory(k=2),\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"Hi, what's up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df96c258-801c-4914-9f7e-d0b66014a082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, what's up\n",
      "AI: Hello! I'm an AI designed to assist with various tasks and provide information. Right now, I'm here to chat with you. How can I help you today?\n",
      "Human: What's their issues?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry, could you please clarify what you mean by \"their issues\"? Are you referring to a specific group of people or a particular topic?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"What's their issues?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8d8764-0dac-492d-a7e0-6100ba3d8c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, what's up\n",
      "AI: Hello! I'm an AI designed to assist with various tasks and provide information. Right now, I'm here to chat with you. How can I help you today?\n",
      "Human: What's their issues?\n",
      "AI: I'm sorry, could you please clarify what you mean by \"their issues\"? Are you referring to a specific group of people or a particular topic?\n",
      "Human: Is it going well?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry, could you please provide more context for your question? What specifically are you referring to when you ask if \"it\" is going well?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Is it going well?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8079f4ab-bafd-49af-b159-617f482bd4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What's their issues?\n",
      "AI: I'm sorry, could you please clarify what you mean by \"their issues\"? Are you referring to a specific group of people or a particular topic?\n",
      "Human: Is it going well?\n",
      "AI: I'm sorry, could you please provide more context for your question? What specifically are you referring to when you ask if \"it\" is going well?\n",
      "Human: What's the solution?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have enough information to provide a specific solution. Could you please provide more context or specify what problem you are referring to?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice here that the first interaction does not appear.\n",
    "conversation_with_summary.predict(input=\"What's the solution?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94266d72-cbee-4829-afeb-a300fbf5f2ca",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50dbf91-b121-4c77-a6b8-928fa9739e0a",
   "metadata": {},
   "source": [
    "`ConversationSummaryBufferMemory` 在内存中保留了最近的交互缓冲区，但不仅仅是完全清除旧的交互，而是将它们编译成摘要并同时使用。与以前的实现不同的是，它使用标记长度而不是交互次数来确定何时清除交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dbdae3f-1fc3-4235-bba3-2e7001207b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(\n",
    "    openai_api_key=\"sk-SJBPQGvGY6P31aLpks0X6s1VaR75hgPlvdF181UESvtLNMer\", \n",
    "    openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1b74d3-44fe-4949-86f3-c7b9f475a74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human and AI exchange greetings and both say they are not doing much.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = memory.chat_memory.messages\n",
    "previous_summary = \"\"\n",
    "memory.predict_new_summary(messages, previous_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa26115-1df9-4661-bbd2-cf50d1034b32",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9f463-ab1b-46c9-9bc0-bbb1c46c2848",
   "metadata": {},
   "source": [
    "`ConversationSummaryMemory`。这种类型的记忆会随着时间的推移对谈话进行总结。这种内存对于较长的对话非常有用，在这种情况下，在提示中逐字保存过去的消息历史会占用太多的令牌。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e98abd-efe4-4b83-a90f-8be6ea48d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(\n",
    "    openai_api_key=\"sk-SJBPQGvGY6P31aLpks0X6s1VaR75hgPlvdF181UESvtLNMer\", \n",
    "    openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72aecd22-c3ea-4e1c-b7f0-533fe1e68006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI and asks how it is doing. The AI responds by asking what is going on.\\nHuman: not much you\\nAI: not much'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b44d2c-6d5f-4acd-8f49-af5546a85ed1",
   "metadata": {},
   "source": [
    "**初始化消息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c2dfa86-7473-4fd3-b058-168f43af29d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human greets the AI with a simple \"hi\" and the AI responds with a friendly \"hi there!\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"hi\")\n",
    "history.add_ai_message(\"hi there!\")\n",
    "\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=llm,\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b306a2-8c7d-42f6-9e3d-d1b40963017c",
   "metadata": {},
   "source": [
    "**结合chain使用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "133747aa-7264-4dc5-ae2c-0387e307a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm=OpenAI(\n",
    "    openai_api_key=\"sk-SJBPQGvGY6P31aLpks0X6s1VaR75hgPlvdF181UESvtLNMer\", \n",
    "    openai_api_base=\"https://api.chatanywhere.com.cn/v1\",\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=ConversationSummaryMemory(llm=llm),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "532716ae-bb5f-4333-9621-fb8ff43d557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm an AI designed to assist with various tasks and provide information. Right now, I'm here to chat with you. How can I help you today?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Hi, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b75879ab-e464-4a5b-8a67-82a1ccf12b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI and asks what it is doing. The AI explains that it is an AI designed to assist with tasks and provide information, and it is currently available to chat and help the human.\n",
      "Human: Tell me more about it!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Of course! I'm an AI, which stands for Artificial Intelligence. I've been designed to assist with various tasks and provide information to users like yourself. My purpose is to make your life easier by answering questions, helping with tasks, and engaging in friendly conversations. I'm constantly learning and improving, so the more you interact with me, the better I become at understanding and assisting you. Is there anything specific you'd like to know or discuss?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Tell me more about it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64ef48d-6799-4fc2-8e55-b6a5c6c8d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI and asks what it is doing. The AI explains that it is an AI designed to assist with tasks and provide information, and it is currently available to chat and help the human. The AI further explains that it is constantly learning and improving, with the goal of making the human's life easier by answering questions, helping with tasks, and engaging in friendly conversations. The AI asks if there is anything specific the human would like to know or discuss.\n",
      "Human: Very cool -- what is the scope of the project?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thank you! The scope of the project is quite broad. As an AI, I am designed to assist with a wide range of tasks and provide information on various topics. I can help with things like answering questions, providing recommendations, assisting with research, and even engaging in friendly conversations. My goal is to be as helpful as possible and make your life easier. Is there anything specific you would like to know or discuss?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Very cool -- what is the scope of the project?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8095f0-3cb2-4cd1-8be9-62d877da7547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
